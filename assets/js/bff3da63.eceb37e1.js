"use strict";(self.webpackChunkcool_docs=self.webpackChunkcool_docs||[]).push([[6005],{3905:function(e,t,n){n.d(t,{Zo:function(){return h},kt:function(){return u}});var a=n(7294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var c=a.createContext({}),l=function(e){var t=a.useContext(c),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},h=function(e){var t=l(e.components);return a.createElement(c.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},d=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,r=e.originalType,c=e.parentName,h=s(e,["components","mdxType","originalType","parentName"]),d=l(n),u=o,m=d["".concat(c,".").concat(u)]||d[u]||p[u]||r;return n?a.createElement(m,i(i({ref:t},h),{},{components:n})):a.createElement(m,i({ref:t},h))}));function u(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=n.length,i=new Array(r);i[0]=d;var s={};for(var c in t)hasOwnProperty.call(t,c)&&(s[c]=t[c]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var l=2;l<r;l++)i[l]=n[l];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}d.displayName="MDXCreateElement"},6613:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return s},contentTitle:function(){return c},metadata:function(){return l},assets:function(){return h},toc:function(){return p},default:function(){return u}});var a=n(7462),o=n(3366),r=(n(7294),n(3905)),i=["components"],s={title:"Introduction to raymarching",author:"Yvan Smorag"},c=void 0,l={permalink:"/blog/2022/07/04/an-introduction-to-raymarching",source:"@site/blog/2022-07-04-an-introduction-to-raymarching.md",title:"Introduction to raymarching",description:'Cool is a software aimed at visual generative art, meaning it has to render - display a 2D or 3D scene onto a computer screen. To do so, Cool uses a specific technique called "Ray Marching" - fairly uncommon among computer graphic softwares, allowing for instance, a very quick rendering of scene with a lot of identical objects (a space filled with infinite spheres for example).',date:"2022-07-04T00:00:00.000Z",formattedDate:"July 4, 2022",tags:[],readingTime:7.76,truncated:!0,authors:[{name:"Yvan Smorag"}],frontMatter:{title:"Introduction to raymarching",author:"Yvan Smorag"},nextItem:{title:"What is cool good at (and not that good) at ? - title to change -",permalink:"/blog/2022/07/04/cool-pros-and-cons"}},h={authorsImageUrls:[void 0]},p=[{value:"IMAGE INFINI ?",id:"image-infini-",children:[],level:3},{value:"How do you represent a 3D image on a 2D screen ?",id:"how-do-you-represent-a-3d-image-on-a-2d-screen-",children:[],level:3},{value:"Colors",id:"colors",children:[],level:3},{value:"SHEMA VISION ?",id:"shema-vision-",children:[{value:"SHEMA RAYTRACING SCRATCHA PIXEL",id:"shema-raytracing-scratcha-pixel",children:[],level:4}],level:3},{value:"Ray Marching",id:"ray-marching",children:[],level:3},{value:"SHEMA RAY MARCHNG 3 SPHERES ? (Le faire moi m\xeame)",id:"shema-ray-marchng-3-spheres--le-faire-moi-m\xeame",children:[],level:3},{value:"Pros and cons of Raymarching",id:"pros-and-cons-of-raymarching",children:[],level:3}],d={toc:p};function u(e){var t=e.components,s=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,a.Z)({},d,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"Cool is a software aimed at visual generative art, meaning it has to ",(0,r.kt)("strong",{parentName:"p"},"render")," - display a 2D or 3D scene onto a computer screen. To do so, Cool uses a specific technique called ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("em",{parentName:"strong"},'"Ray Marching"'))," - fairly uncommon among computer graphic softwares, allowing for instance, a very quick rendering of scene with a lot of identical objects (a space filled with infinite spheres for example).",(0,r.kt)("br",null)),(0,r.kt)("h3",{id:"image-infini-"},"IMAGE INFINI ?"),(0,r.kt)("p",null,"In this article we will present this technique and discuss about the pros and cons compared to other rendering methods used in the industry."),(0,r.kt)("h3",{id:"how-do-you-represent-a-3d-image-on-a-2d-screen-"},"How do you represent a 3D image on a 2D screen ?"),(0,r.kt)("p",null,"A commonly used way to render a 3D scene is called raytracing, but before explainig you how it works, we need to understand how an image is displayed on screen.\nWe have a 3D scene, in which we place a camera (i.e the point of view from where we are looking at the scene). From this point, we are watching a 3D scene that we have now to represent on a 2D plane : our computer screen. In order to do so, the process is exactly the same as for drawing. To draw a scene you are looking at with your eye (the camera), you will use the rule of perspective to project it on paper. For 3D images, we are simply replacing paper by the computer monitor. Eventually, we just have to use the perspective rules for each object of the scene and we will have the shape of our 3d scene. ",(0,r.kt)("em",{parentName:"p"},"Question : Perspective Implement\xe9e naturellement dans OpenGL non ?")," Let's spice it up with colors !"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"perspective",src:n(9599).Z,width:"531",height:"372"})," "),(0,r.kt)("p",null,"Lofe"),(0,r.kt)("h3",{id:"colors"},"Colors"),(0,r.kt)("p",null,"Now that we know how to represent 3d shapes on a 2d screen, we can then make it more realistic, with lights, shadow and colors. In real world, the reason we see objects, is because of ",(0,r.kt)("strong",{parentName:"p"},(0,r.kt)("em",{parentName:"strong"},"photons")),'. They are emitted by sources of light (sun, lamp)..., and will fly through space and time until hitting objects. Once they do so, they have three choices : either being absorbed, re-emitted or transmitted. It is that final bunch of protons emitted and transmitted by the object arriving up to our eyes that will make us "see" the object. For instance, an object reflecting every but "red" photons - light being the sum of all the nuances of colored photons on the visible spectrum - will only emit red photons towards us and therefore look red for the viewer.'),(0,r.kt)("h3",{id:"shema-vision-"},"SHEMA VISION ?"),(0,r.kt)("p",null,"Raytracing is a reversed version of what nature does. Instead of computing the reflection of photons emitted by sources and objects up to the camera (that would take far too long), we are going to cast a ray from our camera through every pixel of our screen, and calculate if this ray intersects with an object of our scene. If so, we check if there are any objects between our sources of light, and the point hit by the ray. We can now draw on our screen : if the ray casted from a specific pixel touches a part of an object, we know that we have to project that part of the object according to the distance between the pixel and the object on that particular pixel following the perspective. In addition, if this part of the object is in direct contact with any source of light, the pixel will be enlightened, otherwise it will be shadowy."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Raytracing",src:n(458).Z,width:"531",height:"464"})),(0,r.kt)("h4",{id:"shema-raytracing-scratcha-pixel"},"SHEMA RAYTRACING SCRATCHA PIXEL"),(0,r.kt)("p",null,"One of the main concerns in the ray tracing method is finding the intersection between the ray you cast through your pixel (which is a straight line), and the shapes composing the objects of your scene. In practice, objects are often composed of thousands of small triangles or squares (= two triangles), and the goal is to find what triangle is touched by the ray sent through the pixel by the camera (\\TROUVER UNE IMAGE MAYBE DE PERSOS DECOMPOSES EN TRIANGLE ?). We know analytically how to test and find an intersection between a straight line (the camera ray) and a triangle but two problems may appear :"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"The more complex your scene, the more triangles you get and therefore the more tests and calculs you have to do meaning a longer render time (for instance rendering a very repetitive pattern, thousands of distorted spheres will be very long all the more in real time)."),(0,r.kt)("li",{parentName:"ol"},"There are some shapes you can't mathematically describe, and therefore you can't analytically find an intersection between itself and the ray defined as a straight line. For instance there are forms that you can't split in small triangles because of their complexity - such as fractals - or/and because it would imply too many triangles to have a good approximation of it and so, \\making render time \\explode.")),(0,r.kt)("p",null,"The question is then : Is there a way to have a fast render for these specific objects (repetitive pattern of objects, fractals...) ? And yes ! Let me introduce to you... ray marching !"),(0,r.kt)("h3",{id:"ray-marching"},"Ray Marching"),(0,r.kt)("p",null,"Let's summarize. To render an object, you will cast a ray - i.e a straight line - from the camera through every pixel of your screen and find how they intersect - or not - with this object to find out how to project this 3D shape onto your 2D computer monitor, following the rules of perspective. One way to find the intersection is to mathematically compute the straight line - shape intersection, and then figure out -by another intersection calculation - how they interact with lights for placing shadows accordingly ; it is ",(0,r.kt)("em",{parentName:"p"},"raytracing"),". Another way to do - and this is what ",(0,r.kt)("em",{parentName:"p"},"cool")," uses - is ",(0,r.kt)("strong",{parentName:"p"},"RayMarching"),'\nRayMarching is a more iterative approach to rendering. Instead of computing an intersection between a straight line and an object, we are going to process by "steps\u201d along each ray shooted. How does it work ? I will show you right away !'),(0,r.kt)("p",null,'At every step, we are going to determine the distance from our current position on the ray - the first step being the camera position - to every object of the scene. If none of these distances is close to zero (meaning that the ray is hitting one object) and if we didn\'t reach the max numbers of step, we move on to the next step : we "march" - hence the name of ray',(0,r.kt)("strong",{parentName:"p"},"Marching")," - of the minimum distance we found between all the objects - in the ray direction. We then repeat the process until the ray meets an object or we arrive at the maximum number of steps. It is an iterative strategy where we march along the ray to determine the collision or not of the ray with the objects within the scene."),(0,r.kt)("p",null,'For instance, if my project contains three spheres. I send a ray through a pixel from the camera. I begin the first step at the camera position, and I compute my distances to these spheres : I found s1:2, s2:3, s3:6 meters. I can then surely advance on the ray direction of at least 2 meters (I am sure i won\'t be "inside" an object). I do so and then compute my distances : s1:4, s3:2, s3:1 meters. I advance 1 meter and check the distances again : s1:5, s2:0.01, s3:2.\n',(0,r.kt)("strong",{parentName:"p"},"0.01")," is close enough in my definition to say that the ray is hitting something - here sphere 2. So, I can send to my render algorithm, that on this pixel, 3 meters away following the camera direction (the distance I advanced along the ray in two steps : 2+1) is a part of sphere2, and render it accordingly."),(0,r.kt)("h3",{id:"shema-ray-marchng-3-spheres--le-faire-moi-m\xeame"},"SHEMA RAY MARCHNG 3 SPHERES ? (Le faire moi m\xeame)"),(0,r.kt)("p",null,"Thus, unlike raytracing, the issues are not mathematically finding an intersection point, but figuring out an expression of the distance position on the ray to object shape or outline, which is far easier for certain objects (LESQUELS ?).\nFor example, we can define a distance from any point in space (x, y, z) to a sphere s of center c, and radius r by the formula ",(0,r.kt)("em",{parentName:"p"},"(first and only math/code function you will see in this page, I promise)")," :"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-c"},"distance(p, s) = distance(p, c) - r; //Distance between the center of the sphere\n                                //and the point minus the radius of the sphere\n")),(0,r.kt)("p",null,"(SHEMA ?)"),(0,r.kt)("p",null,"For a mathematical and coding development, see the bibliography ! \ud83d\ude04 (rajouter lien \xe0 biblio)"),(0,r.kt)("h3",{id:"pros-and-cons-of-raymarching"},"Pros and cons of Raymarching"),(0,r.kt)("p",null,"So, why did we choose to use rayMarching ? (A review avec Jules)"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Innovative. Few softwares use it : allow creativity and a different approach to generative and procedural art (transition pt2)"),(0,r.kt)("li",{parentName:"ol"},'RayMarching and cool workflow ==> Combine, blend, twist and apply a lot of different effects of "basic" shapes easy to do in raymarching, allowing to quickly create weird forms, that may be different or more difficult to achieve in other 3D softwares'),(0,r.kt)("li",{parentName:"ol"},'Very quick render of a big number of the same objects (meshes vs distance comparison) : possibility to "infinitely" fill a space with a certain shape and navigate through it far fluidier than with meshes : very good for procedural worlds and art in general.')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"infinite_sphere",src:n(2700).Z,width:"1920",height:"1080"})),(0,r.kt)("p",null,"Autre chose ?"))}u.isMDXComponent=!0},2700:function(e,t,n){t.Z=n.p+"assets/images/Infinite_Sphere-cfda220542f0043cbf56410633e8c8ff.png"},9599:function(e,t,n){t.Z=n.p+"assets/images/Perspective-cdb70c86cb3e1609a4ed3f3686b24cfa.gif"},458:function(e,t,n){t.Z=n.p+"assets/images/RayTracing_gif-6533954310aa53e2681a210f29839acd.gif"}}]);